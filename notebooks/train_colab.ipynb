{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a27193f",
   "metadata": {},
   "source": [
    "# Electrical Symbol Detection - Training on Google Colab\n",
    "Train ResNet50+FPN model with CIoU Loss for multi-class object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02224d9",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ccf54ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "PyTorch version: 2.9.0+cu128\n",
      "CUDA available: True\n",
      "GPU: NVIDIA A100-SXM4-40GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU: Not available (will use CPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca866290",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive (for saving checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "816236c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "‚úì Google Drive mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Check if running on Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive', force_remount=False)\n",
    "        print(\"‚úì Google Drive mounted at /content/drive\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Could not mount Google Drive: {e}\")\n",
    "        print(\"Proceeding without Drive - checkpoints will save locally in /content/\")\n",
    "else:\n",
    "    print(\"‚ö† Running locally (not on Google Colab)\")\n",
    "    print(\"Dataset will be saved locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058ff92",
   "metadata": {},
   "source": [
    "## 3. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d48470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already exists at /content/symbol-detection\n",
      "Repository updated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "repo_path = '/content/symbol-detection'\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/BhanukaDev/symbol-detection.git', repo_path], check=True)\n",
    "    print(f\"Repository cloned to {repo_path}\")\n",
    "else:\n",
    "    print(f\"Repository already exists at {repo_path}\")\n",
    "    os.chdir(repo_path)\n",
    "    subprocess.run(['git', 'pull'], check=True)\n",
    "    print(\"Repository updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d258df9",
   "metadata": {},
   "source": [
    "## 4. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98667bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu128)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu128)\n",
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (2.0.11)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.24)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (82.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (26.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (1.4.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.3)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (0.21.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub->timm) (8.3.1)\n",
      "Obtaining file:///content/symbol-detection/python\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from symbol-detection==0.1.0) (2.0.2)\n",
      "Requirement already satisfied: opencv-python>=4.8 in /usr/local/lib/python3.12/dist-packages (from symbol-detection==0.1.0) (4.13.0.92)\n",
      "Requirement already satisfied: Pillow>=10.0 in /usr/local/lib/python3.12/dist-packages (from symbol-detection==0.1.0) (11.3.0)\n",
      "Collecting effects (from symbol-detection==0.1.0)\n",
      "  Using cached effects-0.0.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: pip is looking at multiple versions of symbol-detection to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement floor-grid (from symbol-detection) (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for floor-grid\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change to python directory if in Colab\n",
    "if os.path.exists('/content/symbol-detection/python'):\n",
    "    os.chdir('/content/symbol-detection/python')\n",
    "    \n",
    "    # Install local workspace packages first\n",
    "    print(\"Installing local workspace packages...\")\n",
    "    !pip install -e ./floor-grid\n",
    "    !pip install -e ./effects\n",
    "    print(\"‚úì Workspace packages installed\")\n",
    "\n",
    "# Install external dependencies\n",
    "!pip install torch torchvision torchmetrics pycocotools timm\n",
    "\n",
    "# Install main package\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac8408",
   "metadata": {},
   "source": [
    "## 5. Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b773818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbol_detection.training import Trainer, CIoULoss\n",
    "from symbol_detection.dataset.generator import COCODatasetGenerator\n",
    "\n",
    "print(\"‚úì symbol-detection package imported successfully\")\n",
    "print(f\"‚úì Trainer available\")\n",
    "print(f\"‚úì CIoU Loss available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b5d16",
   "metadata": {},
   "source": [
    "## 6. Mount Dataset Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf25f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Determine paths based on environment\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "DRIVE_MOUNTED = os.path.exists('/content/drive/MyDrive') if IN_COLAB else False\n",
    "\n",
    "if IN_COLAB and DRIVE_MOUNTED:\n",
    "    # Save to Google Drive\n",
    "    dataset_dir = '/content/drive/MyDrive/symbol-detection/dataset'\n",
    "    checkpoints_dir = '/content/drive/MyDrive/symbol-detection/checkpoints'\n",
    "    print(\"‚úì Using Google Drive for storage\")\n",
    "elif IN_COLAB:\n",
    "    # Fallback to temporary Colab storage\n",
    "    dataset_dir = '/content/symbol-detection/dataset'\n",
    "    checkpoints_dir = '/content/symbol-detection/checkpoints'\n",
    "    print(\"‚ö† Google Drive not mounted - using temporary Colab storage\")\n",
    "else:\n",
    "    # Local development\n",
    "    dataset_dir = str(Path.cwd().parent.parent / 'python' / 'dataset')\n",
    "    checkpoints_dir = str(Path.cwd().parent.parent / 'python' / 'checkpoints')\n",
    "    print(\"üìÅ Using local storage\")\n",
    "\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset directory: {dataset_dir}\")\n",
    "print(f\"Checkpoints directory: {checkpoints_dir}\")\n",
    "print(f\"Dataset exists: {os.path.exists(os.path.join(dataset_dir, 'annotations.json'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c3ae8",
   "metadata": {},
   "source": [
    "## 7. Generate Dataset (Optional - if not using pre-generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d1440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this if you already have dataset_dir/annotations.json\n",
    "# Uncomment to generate dataset on Colab\n",
    "\n",
    "# from symbol_detection.dataset.generator import COCODatasetGenerator\n",
    "# \n",
    "# generator = COCODatasetGenerator(\n",
    "#     dataset_dir=dataset_dir,\n",
    "#     rows_min=20, rows_max=40,\n",
    "#     cols_min=20, cols_max=40,\n",
    "#     cell_size_min=20, cell_size_max=25,\n",
    "# )\n",
    "# \n",
    "# generator.generate_dataset(\n",
    "#     num_images=500,\n",
    "#     apply_symbol_effects=True,\n",
    "#     apply_image_effects=True,\n",
    "# )\n",
    "# print(f\"Dataset generated: {len(os.listdir(os.path.join(dataset_dir, 'images')))} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb4f6a",
   "metadata": {},
   "source": [
    "## 8. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee327d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "# Adjust batch_size based on GPU:\n",
    "# - T4 (12GB): batch_size=4\n",
    "# - A100 (40GB): batch_size=8-16\n",
    "# - V100 (32GB): batch_size=8\n",
    "\n",
    "training_config = {\n",
    "    'num_epochs': 10,  # Reduced for testing\n",
    "    'batch_size': 4,   # Reduced for T4 GPU\n",
    "    'learning_rate': 0.005,\n",
    "    'num_classes': 7,  # Electrical symbols\n",
    "    'use_ciou_loss': True,  # Use Complete IoU Loss\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"\\n‚ö†Ô∏è Using 10 epochs for quick test. Increase to 50+ for production training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022d931",
   "metadata": {},
   "source": [
    "## 9. Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symbol_detection.training import Trainer\n",
    "import torch\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    dataset_dir=dataset_dir,\n",
    "    output_dir=checkpoints_dir,\n",
    "    num_classes=training_config['num_classes'],\n",
    "    batch_size=training_config['batch_size'],\n",
    "    learning_rate=training_config['learning_rate'],\n",
    "    num_epochs=training_config['num_epochs'],\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    use_ciou_loss=training_config['use_ciou_loss'],\n",
    ")\n",
    "\n",
    "print(f\"Trainer initialized on device: {trainer.device}\")\n",
    "print(f\"Model: FasterRCNN with ResNet50+FPN backbone\")\n",
    "print(f\"CIoU Loss: {training_config['use_ciou_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac285d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "try:\n",
    "    trainer.train()\n",
    "    print(\"\\n‚úì Training completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097739c",
   "metadata": {},
   "source": [
    "## 10. Visualize Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d121d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "metrics_file = Path(checkpoints_dir) / 'metrics.json'\n",
    "\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(metrics['train_losses'], label='Train Loss', marker='o')\n",
    "    plt.plot(metrics['val_losses'], label='Validation Loss', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{checkpoints_dir}/training_curve.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Final train loss: {metrics['train_losses'][-1]:.4f}\")\n",
    "    print(f\"Final val loss: {metrics['val_losses'][-1]:.4f}\")\n",
    "else:\n",
    "    print(\"Metrics file not found. Training may not have completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8456b18a",
   "metadata": {},
   "source": [
    "## 11. List Saved Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "checkpoints = list(Path(checkpoints_dir).glob('*.pth'))\n",
    "\n",
    "if checkpoints:\n",
    "    print(f\"Saved checkpoints ({len(checkpoints)}):\")\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        size_mb = ckpt.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  {ckpt.name} ({size_mb:.1f} MB)\")\n",
    "    print(f\"\\nLatest checkpoint: {max(checkpoints, key=lambda x: x.stat().st_mtime).name}\")\n",
    "else:\n",
    "    print(\"No checkpoints found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c50dd4e",
   "metadata": {},
   "source": [
    "## 12. Download Best Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063859b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The models are already saved in Google Drive (/content/drive/MyDrive/symbol-detection/checkpoints/)\n",
    "# You can download them directly from Google Drive or use the Colab files interface\n",
    "\n",
    "print(f\"Checkpoints saved to: {checkpoints_dir}\")\n",
    "print(\"You can download them from Google Drive or use the Colab Files panel on the left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
